{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f615f93",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f51ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from obspy.clients.fdsn import Client\n",
    "from shapely.geometry import Point, box\n",
    "\n",
    "from pygeohydro import WBD\n",
    "\n",
    "#warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "#warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_huc_geometries_local(huc_level, geom_gdf):\n",
    "    \"\"\"\n",
    "    Fetch HUC geometries locally using USGS WBD via pygeohydro.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    huc_level : str or int\n",
    "        HUC level ('02','04','06','08','10','12' or 2,4,6,8,10,12)\n",
    "    geom_gdf : geopandas.GeoDataFrame\n",
    "        GeoDataFrame containing geometry (e.g., bbox or AOI)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        HUC geometries intersecting the input geometry\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize HUC level\n",
    "    huc_level = f\"huc{int(huc_level)}\"\n",
    "\n",
    "    # Initialize WBD\n",
    "    wbd = WBD(huc_level)\n",
    "\n",
    "    # Extract shapely geometry (first feature)\n",
    "    geom = geom_gdf.geometry.iloc[0]\n",
    "\n",
    "    # Fetch HUCs intersecting geometry\n",
    "    huc_gdf = wbd.bygeom(geom)\n",
    "\n",
    "    return huc_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54059af",
   "metadata": {},
   "source": [
    "## User Configuration\n",
    "\n",
    "Basins are auto-discovered from basin names by querying USGS WBD HUC geometries using `easysnowdata`.\n",
    "\n",
    "Notes:\n",
    "- This approach uses Google Earth Engine under the hood; you may need to authenticate once.\n",
    "- `bbox_wa` should tightly bound your study region to keep queries fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f04afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION ==========\n",
    "\n",
    "# List of basin names to search for\n",
    "basin_names = [\n",
    "    \"Skagit\",\n",
    "    \"Nooksack\",\n",
    "    \"Skykomish\",\n",
    "    \"Snoqualmie\",\n",
    "    \"Cedar\",  # Cedar River watershed (not Cedar Creek)\n",
    "    \"Green\",\n",
    "    \"Puyallup\",\n",
    "    \"Carbon\",\n",
    "    \"Nisqually\",\n",
    "    \"Cowlitz\",\n",
    "]\n",
    "\n",
    "# HUC level to query (8, 10, or 12)\n",
    "huc_level = 4\n",
    "\n",
    "# FDSN client for station queries\n",
    "fdsn_provider = \"IRIS\"\n",
    "\n",
    "# Bounding box for western Washington (minlon, minlat, maxlon, maxlat)\n",
    "# This should encompass all basins of interest\n",
    "bbox_wa = (-124.8, 45.5, -120.0, 49.0)\n",
    "\n",
    "# Optional: Filter stations by elevation (meters)\n",
    "# Set to None to disable filtering\n",
    "elev_min = None  # Example: 0 (sea level)\n",
    "elev_max = None  # Example: 3000 (3000 meters)\n",
    "\n",
    "# Optional: Filter by specific networks\n",
    "# Set to None to include all networks\n",
    "network_filter = [\"UW\", \"CC\"]  # UW + CC (as requested)\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path(\".\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  HUC Level: {huc_level}\")\n",
    "print(f\"  FDSN Provider: {fdsn_provider}\")\n",
    "print(f\"  Bounding Box: {bbox_wa}\")\n",
    "print(f\"  Elevation Filter: {elev_min} to {elev_max}\")\n",
    "print(f\"  Network Filter: {network_filter}\")\n",
    "print(f\"  Output Directory: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7c1fc",
   "metadata": {},
   "source": [
    "## Step 1: Discover HUC Codes from Basin Names\n",
    "\n",
    "Query the USGS WBD database to find HUC codes for each basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” Discovering HUC codes for basins...\")\n",
    "print(f\"Searching for {len(basin_names)} basins in western Washington\\n\")\n",
    "\n",
    "# HUC level string expected by easysnowdata (e.g., '08', '10', '12')\n",
    "huc_level_str = f\"{huc_level:02d}\"\n",
    "code_col = f\"huc{int(huc_level_str)}\"\n",
    "\n",
    "# Create geometry from bounding box (box already imported from shapely.geometry)\n",
    "bbox_geom = box(*bbox_wa)\n",
    "\n",
    "print(f\"Using HUC level: {huc_level_str} (code column: {code_col})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c89dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning Slow (5min+) for HUC10 over large area.\n",
    "hucs_all = get_huc_geometries_local(\n",
    "    huc_level=huc_level_str,\n",
    "    geom_gdf=gpd.GeoDataFrame(geometry=[bbox_geom], crs=\"EPSG:4326\"),\n",
    ")\n",
    "hucs_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4080a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one to understand structure\n",
    "hucs_all.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hucs_all.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7569da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {len(hucs_all)} HUC polygon(s) in bbox.\")\n",
    "print('Columns:', list(hucs_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c058943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sub-basin polygons from HUCs and a dissolved basin polygon per basin_name\n",
    "\n",
    "if 'name' not in hucs_all.columns:\n",
    "    raise KeyError(f\"Expected a 'name' column in HUC data. Columns: {list(hucs_all.columns)}\")\n",
    "if code_col not in hucs_all.columns:\n",
    "    raise KeyError(f\"Expected code column '{code_col}' in HUC data. Columns: {list(hucs_all.columns)}\")\n",
    "\n",
    "records = []\n",
    "name_series = hucs_all['name'].astype(str)\n",
    "\n",
    "print('Matching basin names to HUC polygons...')\n",
    "for basin_name in basin_names:\n",
    "    basin_hucs = hucs_all[name_series.str.contains(basin_name, case=False, na=False)].copy()\n",
    "    basin_hucs[code_col] = basin_hucs[code_col].astype(str)\n",
    "\n",
    "    if len(basin_hucs) == 0:\n",
    "        print(f\"  {basin_name:15s}: âš ï¸ 0 HUC polygons matched\")\n",
    "        continue\n",
    "\n",
    "    basin_hucs['basin_name'] = basin_name\n",
    "    records.append(basin_hucs[['basin_name', 'name', code_col, 'geometry']])\n",
    "    print(f\"  {basin_name:15s}: âœ“ {len(basin_hucs)} HUC polygon(s)\")\n",
    "\n",
    "if len(records) == 0:\n",
    "    raise RuntimeError('No HUC polygons matched your basin_names. Consider adjusting basin_names or bbox_wa.')\n",
    "\n",
    "subbasins_gdf = gpd.GeoDataFrame(pd.concat(records, ignore_index=True), crs='EPSG:4326')\n",
    "subbasins_gdf = subbasins_gdf.rename(columns={'name': 'huc_name', code_col: 'huc_code'})\n",
    "\n",
    "# Dissolve to one polygon per basin_name (for basin-level station association)\n",
    "basins_gdf = subbasins_gdf.dissolve(by='basin_name', as_index=False)[['basin_name', 'geometry']]\n",
    "\n",
    "# Attach the list of HUC codes used for each basin (string for CSV friendliness)\n",
    "codes_by_basin = (\n",
    "    subbasins_gdf.groupby('basin_name')['huc_code']\n",
    "    .apply(lambda s: ';'.join(sorted(set(s.astype(str)))))\n",
    "    .reset_index()\n",
    "    .rename(columns={'huc_code': 'huc_code'})\n",
    ")\n",
    "basins_gdf = basins_gdf.merge(codes_by_basin, on='basin_name', how='left')\n",
    "\n",
    "total_unique_hucs = subbasins_gdf['huc_code'].nunique()\n",
    "print('-' * 70)\n",
    "print(f\"Matched HUC polygons: {len(subbasins_gdf)} (unique HUC codes: {total_unique_hucs})\")\n",
    "print('  subbasins_gdf rows:', len(subbasins_gdf))\n",
    "print('  basins_gdf rows:', len(basins_gdf))\n",
    "display(basins_gdf[['basin_name', 'huc_code']])\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75abbb5",
   "metadata": {},
   "source": [
    "## Step 2: Fetch Seismic Stations (UW, CC)\n",
    "\n",
    "Query station metadata from the FDSN provider and convert results to a GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dec18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch stations for UW + CC networks within bbox_wa\n",
    "client = Client(fdsn_provider)\n",
    "\n",
    "networks = network_filter if network_filter is not None else None\n",
    "network_arg = ','.join(networks) if networks else '*'\n",
    "\n",
    "print(f\"Requesting stations from {fdsn_provider} for network={network_arg}\")\n",
    "inv = client.get_stations(\n",
    "    network=network_arg,\n",
    "    level='station',\n",
    "    minlongitude=bbox_wa[0],\n",
    "    minlatitude=bbox_wa[1],\n",
    "    maxlongitude=bbox_wa[2],\n",
    "    maxlatitude=bbox_wa[3],\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for net in inv:\n",
    "    for sta in net:\n",
    "        rows.append(\n",
    "            {\n",
    "                'network': net.code,\n",
    "                'station': sta.code,\n",
    "                'latitude': float(sta.latitude),\n",
    "                'longitude': float(sta.longitude),\n",
    "                'elevation_m': float(sta.elevation) if sta.elevation is not None else np.nan,\n",
    "                'start_date': getattr(sta, 'start_date', None),\n",
    "                'end_date': getattr(sta, 'end_date', None),\n",
    "            }\n",
    ")\n",
    "\n",
    "stations_df = pd.DataFrame(rows)\n",
    "if len(stations_df) == 0:\n",
    "    raise RuntimeError('No stations returned. Check bbox_wa, network_filter, and fdsn_provider.')\n",
    "\n",
    "# Optional elevation filter\n",
    "if elev_min is not None:\n",
    "    stations_df = stations_df[stations_df['elevation_m'] >= float(elev_min)]\n",
    "if elev_max is not None:\n",
    "    stations_df = stations_df[stations_df['elevation_m'] <= float(elev_max)]\n",
    "\n",
    "stations_gdf = gpd.GeoDataFrame(\n",
    "    stations_df,\n",
    "    geometry=gpd.points_from_xy(stations_df['longitude'], stations_df['latitude']),\n",
    "    crs='EPSG:4326',\n",
    ")\n",
    "\n",
    "print(f\"Stations fetched: {len(stations_gdf)}\")\n",
    "display(stations_gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfed49d",
   "metadata": {},
   "source": [
    "## Step 3: Associate Stations with Basins/Sub-basins\n",
    "\n",
    "Spatially join station points to dissolved basins and to sub-basin HUC polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60066da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basin-level join (dissolved polygons)\n",
    "stations_basin = gpd.sjoin(\n",
    "    stations_gdf,\n",
    "    basins_gdf[['basin_name', 'geometry']],\n",
    "    how='left',\n",
    "    predicate='within',\n",
    ")\n",
    "stations_basin = stations_basin.drop(columns=[c for c in ['index_right'] if c in stations_basin.columns])\n",
    "\n",
    "# Sub-basin join (HUC polygons)\n",
    "stations_subbasin = gpd.sjoin(\n",
    "    stations_gdf,\n",
    "    subbasins_gdf[['basin_name', 'huc_code', 'huc_name', 'geometry']],\n",
    "    how='left',\n",
    "    predicate='within',\n",
    ")\n",
    "stations_subbasin = stations_subbasin.drop(columns=[c for c in ['index_right'] if c in stations_subbasin.columns])\n",
    "\n",
    "key_cols = ['network', 'station']\n",
    "\n",
    "# If a station falls into multiple polygons, keep the first match deterministically\n",
    "stations_basin_first = stations_basin.sort_values(key_cols).drop_duplicates(subset=key_cols)\n",
    "stations_subbasin_first = stations_subbasin.sort_values(key_cols).drop_duplicates(subset=key_cols)\n",
    "\n",
    "stations_with_basins = stations_gdf.merge(\n",
    "    stations_basin_first[key_cols + ['basin_name']].rename(columns={'basin_name': 'basin_name_basin'}),\n",
    "    on=key_cols,\n",
    "    how='left',\n",
    ")\n",
    "stations_with_basins = stations_with_basins.merge(\n",
    "    stations_subbasin_first[key_cols + ['basin_name', 'huc_code', 'huc_name']].rename(\n",
    "        columns={'basin_name': 'basin_name_subbasin'}\n",
    "    ),\n",
    "    on=key_cols,\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "# Prefer subbasin-derived basin name when present\n",
    "stations_with_basins['basin_name'] = stations_with_basins['basin_name_subbasin'].combine_first(\n",
    "    stations_with_basins['basin_name_basin']\n",
    " )\n",
    "\n",
    "stations_with_basins = stations_with_basins.drop(columns=['basin_name_basin', 'basin_name_subbasin'])\n",
    "\n",
    "assigned = stations_with_basins['basin_name'].notna().sum()\n",
    "print(f\"Stations assigned to a basin: {assigned} / {len(stations_with_basins)}\")\n",
    "display(stations_with_basins[['network','station','basin_name','huc_code','huc_name']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb278f68",
   "metadata": {},
   "source": [
    "## Step 4: QC Map (Basins + Stations)\n",
    "\n",
    "Color-code each basin and plot associated stations on top for visual QA/QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Create a stable color map for basin names\n",
    "basin_list = list(basins_gdf['basin_name'])\n",
    "cmap = plt.get_cmap('tab20', max(len(basin_list), 1))\n",
    "basin_colors = {name: cmap(i) for i, name in enumerate(basin_list)}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot basins\n",
    "basins_gdf.plot(\n",
    "    ax=ax,\n",
    "    facecolor=basins_gdf['basin_name'].map(basin_colors),\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8,\n",
    "    alpha=0.35,\n",
    ")\n",
    "\n",
    "# Plot stations\n",
    "assigned_mask = stations_with_basins['basin_name'].notna()\n",
    "assigned_gdf = stations_with_basins[assigned_mask].copy()\n",
    "unassigned_gdf = stations_with_basins[~assigned_mask].copy()\n",
    "\n",
    "if len(assigned_gdf) > 0:\n",
    "    assigned_gdf.plot(\n",
    "        ax=ax,\n",
    "        markersize=25,\n",
    "        color=assigned_gdf['basin_name'].map(basin_colors),\n",
    "        edgecolor='white',\n",
    "        linewidth=0.4,\n",
    "        zorder=5,\n",
    "    )\n",
    "\n",
    "if len(unassigned_gdf) > 0:\n",
    "    unassigned_gdf.plot(\n",
    "        ax=ax,\n",
    "        markersize=35,\n",
    "        color='black',\n",
    "        marker='x',\n",
    "        zorder=6,\n",
    "    )\n",
    "\n",
    "# Legend\n",
    "legend_handles = [mpatches.Patch(color=basin_colors[n], label=n) for n in basin_list]\n",
    "if len(unassigned_gdf) > 0:\n",
    "    legend_handles.append(mpatches.Patch(color='black', label='Unassigned (outside basins)'))\n",
    "ax.legend(handles=legend_handles, loc='upper right', frameon=True)\n",
    "\n",
    "ax.set_title('Basins (dissolved) + UW/CC Stations (color-coded by basin)')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Tighten to bbox (with a small pad)\n",
    "minlon, minlat, maxlon, maxlat = bbox_wa\n",
    "pad_lon = (maxlon - minlon) * 0.02\n",
    "pad_lat = (maxlat - minlat) * 0.02\n",
    "ax.set_xlim(minlon - pad_lon, maxlon + pad_lon)\n",
    "ax.set_ylim(minlat - pad_lat, maxlat + pad_lat)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "qc_path = output_dir / 'qc_basins_stations.png'\n",
    "fig.savefig(qc_path, dpi=200, bbox_inches='tight')\n",
    "print(f\"Saved QC map: {qc_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109e3db",
   "metadata": {},
   "source": [
    "## Step 5: Export CSV\n",
    "\n",
    "Write station metadata + basin/HUC assignment to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export station assignments to CSV\n",
    "csv_path = output_dir / 'stations_by_basin.csv'\n",
    "\n",
    "export_cols = [\n",
    "    'network',\n",
    "    'station',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'elevation_m',\n",
    "    'basin_name',\n",
    "    'huc_code',\n",
    "    'huc_name',\n",
    "    'start_date',\n",
    "    'end_date',\n",
    "]\n",
    "\n",
    "stations_out = stations_with_basins.copy()\n",
    "for c in export_cols:\n",
    "    if c not in stations_out.columns:\n",
    "        stations_out[c] = np.nan\n",
    "\n",
    "stations_out = pd.DataFrame(stations_out[export_cols])\n",
    "stations_out.to_csv(csv_path, index=False)\n",
    "print(f\"Wrote CSV: {csv_path} ({len(stations_out)} rows)\")\n",
    "\n",
    "display(stations_out.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
