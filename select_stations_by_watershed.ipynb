{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f615f93",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f51ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from obspy.clients.fdsn import Client\n",
    "from shapely.geometry import Point, box\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc57f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /Users/marinedenolle/opt/miniconda3/envs/gaia-hazlab/bin/python\n",
      "pyproj version: 3.7.2\n",
      "PROJ data dir: /Users/marinedenolle/opt/miniconda3/envs/gaia-hazlab/share/proj\n",
      "CRS OK: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# --- CRS/PROJ sanity check (fixes: Invalid projection EPSG:4326 / proj.db not found) ---\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "print('Python executable:', sys.executable)\n",
    "\n",
    "try:\n",
    "    import pyproj\n",
    "    from pyproj import CRS\n",
    "    import pyproj.datadir\n",
    "\n",
    "    # Prefer the conda env PROJ data (contains proj.db + EPSG tables)\n",
    "    conda_prefix = os.environ.get('CONDA_PREFIX')\n",
    "    conda_proj_dir = (\n",
    "        str(pathlib.Path(conda_prefix) / 'share' / 'proj') if conda_prefix else None\n",
    "    )\n",
    "\n",
    "    if conda_proj_dir and (pathlib.Path(conda_proj_dir) / 'proj.db').exists():\n",
    "        pyproj.datadir.set_data_dir(conda_proj_dir)\n",
    "        os.environ.setdefault('PROJ_DATA', conda_proj_dir)\n",
    "        os.environ.setdefault('PROJ_LIB', conda_proj_dir)\n",
    "    else:\n",
    "        # Fallback to pyproj's bundled data dir\n",
    "        proj_data_dir = pyproj.datadir.get_data_dir()\n",
    "        if proj_data_dir:\n",
    "            pyproj.datadir.set_data_dir(proj_data_dir)\n",
    "            os.environ.setdefault('PROJ_DATA', proj_data_dir)\n",
    "            os.environ.setdefault('PROJ_LIB', proj_data_dir)\n",
    "\n",
    "    _ = CRS.from_epsg(4326)\n",
    "    print('pyproj version:', pyproj.__version__)\n",
    "    print('PROJ data dir:', pyproj.datadir.get_data_dir())\n",
    "    print('CRS OK: EPSG:4326')\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        'CRS/PROJ is misconfigured in this Python environment. '\n",
    "        'Recommended fix (conda-forge):\\n'\n",
    "        '  conda install -c conda-forge pyproj proj proj-data geopandas\\n'\n",
    "        'Then restart the notebook kernel.\\n\\n'\n",
    "        f'Original error: {e}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb22299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import easysnowdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54059af",
   "metadata": {},
   "source": [
    "## User Configuration\n",
    "\n",
    "Basins are auto-discovered from basin names by querying USGS WBD HUC geometries using `easysnowdata`.\n",
    "\n",
    "Notes:\n",
    "- This approach uses Google Earth Engine under the hood; you may need to authenticate once.\n",
    "- `bbox_wa` should tightly bound your study region to keep queries fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f04afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  HUC Level: 10\n",
      "  FDSN Provider: IRIS\n",
      "  Bounding Box: (-124.8, 45.5, -120.0, 49.0)\n",
      "  Elevation Filter: None to None\n",
      "  Network Filter: ['UW', 'CC']\n",
      "  Output Directory: /Users/marinedenolle/GitHub/gaia-data-downloaders\n"
     ]
    }
   ],
   "source": [
    "# ========== CONFIGURATION ==========\n",
    "\n",
    "# List of basin names to search for\n",
    "basin_names = [\n",
    "    \"Skagit\",\n",
    "    \"Nooksack\",\n",
    "    \"Skykomish\",\n",
    "    \"Snoqualmie\",\n",
    "    \"Cedar\",  # Cedar River watershed (not Cedar Creek)\n",
    "    \"Green\",\n",
    "    \"Puyallup\",\n",
    "    \"Carbon\",\n",
    "    \"Nisqually\",\n",
    "    \"Cowlitz\",\n",
    "]\n",
    "\n",
    "# HUC level to query (8, 10, or 12)\n",
    "huc_level = 10\n",
    "\n",
    "# FDSN client for station queries\n",
    "fdsn_provider = \"IRIS\"\n",
    "\n",
    "# Bounding box for western Washington (minlon, minlat, maxlon, maxlat)\n",
    "# This should encompass all basins of interest\n",
    "bbox_wa = (-124.8, 45.5, -120.0, 49.0)\n",
    "\n",
    "# Optional: Filter stations by elevation (meters)\n",
    "# Set to None to disable filtering\n",
    "elev_min = None  # Example: 0 (sea level)\n",
    "elev_max = None  # Example: 3000 (3000 meters)\n",
    "\n",
    "# Optional: Filter by specific networks\n",
    "# Set to None to include all networks\n",
    "network_filter = [\"UW\", \"CC\"]  # UW + CC (as requested)\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path(\".\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  HUC Level: {huc_level}\")\n",
    "print(f\"  FDSN Provider: {fdsn_provider}\")\n",
    "print(f\"  Bounding Box: {bbox_wa}\")\n",
    "print(f\"  Elevation Filter: {elev_min} to {elev_max}\")\n",
    "print(f\"  Network Filter: {network_filter}\")\n",
    "print(f\"  Output Directory: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7c1fc",
   "metadata": {},
   "source": [
    "## Step 1: Discover HUC Codes from Basin Names\n",
    "\n",
    "Query the USGS WBD database to find HUC codes for each basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "305a6cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Discovering HUC codes for basins...\n",
      "Searching for 10 basins in western Washington\n",
      "\n",
      "Using HUC level: 10 (code column: huc10)\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” Discovering HUC codes for basins...\")\n",
    "print(f\"Searching for {len(basin_names)} basins in western Washington\\n\")\n",
    "\n",
    "# HUC level string expected by easysnowdata (e.g., '08', '10', '12')\n",
    "huc_level_str = f\"{huc_level:02d}\"\n",
    "code_col = f\"huc{int(huc_level_str)}\"\n",
    "\n",
    "# Create geometry from bounding box (box already imported from shapely.geometry)\n",
    "bbox_geom = box(*bbox_wa)\n",
    "\n",
    "print(f\"Using HUC level: {huc_level_str} (code column: {code_col})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bca550e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "EEException",
     "evalue": "Caller does not have required permission to use project my-project. Grant the caller the roles/serviceusage.serviceUsageConsumer role, or a custom role with the serviceusage.services.use permission, by visiting https://console.developers.google.com/iam-admin/iam/project?project=my-project and then retry. Propagation of the new permission may take a few minutes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/ee/data.py:349\u001b[39m, in \u001b[36m_execute_cloud_call\u001b[39m\u001b[34m(call, num_retries)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient.errors.HttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/googleapiclient/_helpers.py:130\u001b[39m, in \u001b[36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m         logger.warning(message)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/googleapiclient/http.py:938\u001b[39m, in \u001b[36mHttpRequest.execute\u001b[39m\u001b[34m(self, http, num_retries)\u001b[39m\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resp.status >= \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri=\u001b[38;5;28mself\u001b[39m.uri)\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.postproc(resp, content)\n",
      "\u001b[31mHttpError\u001b[39m: <HttpError 403 when requesting https://earthengine-highvolume.googleapis.com/v1/projects/my-project/algorithms?prettyPrint=false&alt=json returned \"Caller does not have required permission to use project my-project. Grant the caller the roles/serviceusage.serviceUsageConsumer role, or a custom role with the serviceusage.services.use permission, by visiting https://console.developers.google.com/iam-admin/iam/project?project=my-project and then retry. Propagation of the new permission may take a few minutes.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'USER_PROJECT_DENIED', 'domain': 'googleapis.com', 'metadata': {'consumer': 'projects/my-project', 'containerInfo': 'my-project', 'service': 'earthengine.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'Caller does not have required permission to use project my-project. Grant the caller the roles/serviceusage.serviceUsageConsumer role, or a custom role with the serviceusage.services.use permission, by visiting https://console.developers.google.com/iam-admin/iam/project?project=my-project and then retry. Propagation of the new permission may take a few minutes.'}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Google developer console IAM admin', 'url': 'https://console.developers.google.com/iam-admin/iam/project?project=my-project'}]}]\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mEEException\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m ee.Authenticate()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mee\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmy-project\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/ee/_utils.py:39\u001b[39m, in \u001b[36maccept_opt_prefix.<locals>.opt_fixed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m new_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m     38\u001b[39m       kwargs[new_key] = old_key_val\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/ee/__init__.py:233\u001b[39m, in \u001b[36mInitialize\u001b[39m\u001b[34m(credentials, url, cloud_api_key, http_transport, project)\u001b[39m\n\u001b[32m    227\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    228\u001b[39m       (adc_err \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    229\u001b[39m       \u001b[38;5;129;01mor\u001b[39;00m (matches \u001b[38;5;129;01mand\u001b[39;00m oauth.is_sdk_project(matches[\u001b[32m1\u001b[39m]))\n\u001b[32m    230\u001b[39m       \u001b[38;5;129;01mor\u001b[39;00m (oauth_project_err \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    231\u001b[39m   ):\n\u001b[32m    232\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EEException(NO_PROJECT_EXCEPTION) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dynamic_class \u001b[38;5;129;01min\u001b[39;00m _DYNAMIC_CLASSES:\n\u001b[32m    236\u001b[39m   dynamic_class.initialize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/ee/__init__.py:215\u001b[39m, in \u001b[36mInitialize\u001b[39m\u001b[34m(credentials, url, cloud_api_key, http_transport, project)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;66;03m# Initialize the dynamically loaded functions on the objects that want them.\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m   \u001b[43mApiFunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EEException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    217\u001b[39m   \u001b[38;5;66;03m# We tried to detect missing projects before initialization, but some cases\u001b[39;00m\n\u001b[32m    218\u001b[39m   \u001b[38;5;66;03m# like Colab hide the project, so check errors from missing projects too.\u001b[39;00m\n\u001b[32m    219\u001b[39m   adc_err = \u001b[33m'\u001b[39m\u001b[33mauthenticating by using local Application Default Credentials\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/ee/apifunction.py:163\u001b[39m, in \u001b[36mApiFunction.initialize\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initializes the list of signatures from the Earth Engine front-end.\"\"\"\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._api:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m   signatures = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetAlgorithms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m   api = {}\n\u001b[32m    165\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m name, sig \u001b[38;5;129;01min\u001b[39;00m signatures.items():\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# Strip type parameters.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/ee/data.py:1439\u001b[39m, in \u001b[36mgetAlgorithms\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1434\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m   1435\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m*** Earth Engine ***\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1436\u001b[39m         response[_INIT_MESSAGE_HEADER],\n\u001b[32m   1437\u001b[39m         file=sys.stderr)\n\u001b[32m   1438\u001b[39m call.add_response_callback(inspect)\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _cloud_api_utils.convert_algorithms(\u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/ee/data.py:351\u001b[39m, in \u001b[36m_execute_cloud_call\u001b[39m\u001b[34m(call, num_retries)\u001b[39m\n\u001b[32m    349\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m call.execute(num_retries=num_retries)\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient.errors.HttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[31mEEException\u001b[39m: Caller does not have required permission to use project my-project. Grant the caller the roles/serviceusage.serviceUsageConsumer role, or a custom role with the serviceusage.services.use permission, by visiting https://console.developers.google.com/iam-admin/iam/project?project=my-project and then retry. Propagation of the new permission may take a few minutes."
     ]
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize(project='my-project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7569da8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Earth Engine is not initialized. If you haven't yet, run `earthengine authenticate` in a terminal, then restart the notebook kernel and re-run this cell. Original error: ee.Initialize: no project found. Call with project= or see http://goo.gle/ee-auth.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEEException\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Fallback to default endpoint if high-volume isn't available\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43mee\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEarth Engine initialized (using saved credentials).\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/ee/_utils.py:39\u001b[39m, in \u001b[36maccept_opt_prefix.<locals>.opt_fixed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m       kwargs[new_key] = old_key_val\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/gaia-hazlab/lib/python3.11/site-packages/ee/__init__.py:232\u001b[39m, in \u001b[36mInitialize\u001b[39m\u001b[34m(credentials, url, cloud_api_key, http_transport, project)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    228\u001b[39m     (adc_err \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    229\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m (matches \u001b[38;5;129;01mand\u001b[39;00m oauth.is_sdk_project(matches[\u001b[32m1\u001b[39m]))\n\u001b[32m    230\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m (oauth_project_err \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    231\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m EEException(NO_PROJECT_EXCEPTION) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[31mEEException\u001b[39m: ee.Initialize: no project found. Call with project= or see http://goo.gle/ee-auth.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEarth Engine initialized (using saved credentials).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEarth Engine is not initialized. If you haven\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yet, run `earthengine authenticate` in a terminal, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthen restart the notebook kernel and re-run this cell. Original error: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[32m     15\u001b[39m     )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Fetch all HUC geometries in the bbox at the requested level\u001b[39;00m\n\u001b[32m     18\u001b[39m huc_level_str = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhuc_level\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: Earth Engine is not initialized. If you haven't yet, run `earthengine authenticate` in a terminal, then restart the notebook kernel and re-run this cell. Original error: ee.Initialize: no project found. Call with project= or see http://goo.gle/ee-auth."
     ]
    }
   ],
   "source": [
    "# Earth Engine setup (required by easysnowdata.hydroclimatology.get_huc_geometries)\n",
    "# You already ran `earthengine authenticate` in the terminal; this cell just initializes EE using that saved token.\n",
    "try:\n",
    "    import ee\n",
    "    try:\n",
    "        ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "    except Exception:\n",
    "        # Fallback to default endpoint if high-volume isn't available\n",
    "        ee.Initialize()\n",
    "    print(\"Earth Engine initialized (using saved credentials).\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"Earth Engine is not initialized. If you haven't yet, run `earthengine authenticate` in a terminal, \"\n",
    "        \"then restart the notebook kernel and re-run this cell. Original error: \" + str(e)\n",
    "    )\n",
    "\n",
    "# Fetch all HUC geometries in the bbox at the requested level\n",
    "huc_level_str = f\"{huc_level:02d}\"\n",
    "code_col = f\"huc{int(huc_level_str)}\"\n",
    "hucs_all = easysnowdata.hydroclimatology.get_huc_geometries(\n",
    "    bbox_input=bbox_wa,\n",
    "    huc_level=huc_level_str,\n",
    ")\n",
    "\n",
    "if hucs_all.crs is None:\n",
    "    hucs_all = hucs_all.set_crs('EPSG:4326')\n",
    "elif hucs_all.crs.to_epsg() != 4326:\n",
    "    hucs_all = hucs_all.to_crs('EPSG:4326')\n",
    "\n",
    "print(f\"Loaded {len(hucs_all)} HUC polygon(s) in bbox.\")\n",
    "print('Columns:', list(hucs_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c058943",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hucs_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Build sub-basin polygons from HUCs and a dissolved basin polygon per basin_name\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhucs_all\u001b[49m.columns:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m\u001b[33m column in HUC data. Columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(hucs_all.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m code_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m hucs_all.columns:\n",
      "\u001b[31mNameError\u001b[39m: name 'hucs_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Build sub-basin polygons from HUCs and a dissolved basin polygon per basin_name\n",
    "\n",
    "if 'name' not in hucs_all.columns:\n",
    "    raise KeyError(f\"Expected a 'name' column in HUC data. Columns: {list(hucs_all.columns)}\")\n",
    "if code_col not in hucs_all.columns:\n",
    "    raise KeyError(f\"Expected code column '{code_col}' in HUC data. Columns: {list(hucs_all.columns)}\")\n",
    "\n",
    "records = []\n",
    "name_series = hucs_all['name'].astype(str)\n",
    "\n",
    "print('Matching basin names to HUC polygons...')\n",
    "for basin_name in basin_names:\n",
    "    basin_hucs = hucs_all[name_series.str.contains(basin_name, case=False, na=False)].copy()\n",
    "    basin_hucs[code_col] = basin_hucs[code_col].astype(str)\n",
    "\n",
    "    if len(basin_hucs) == 0:\n",
    "        print(f\"  {basin_name:15s}: âš ï¸ 0 HUC polygons matched\")\n",
    "        continue\n",
    "\n",
    "    basin_hucs['basin_name'] = basin_name\n",
    "    records.append(basin_hucs[['basin_name', 'name', code_col, 'geometry']])\n",
    "    print(f\"  {basin_name:15s}: âœ“ {len(basin_hucs)} HUC polygon(s)\")\n",
    "\n",
    "if len(records) == 0:\n",
    "    raise RuntimeError('No HUC polygons matched your basin_names. Consider adjusting basin_names or bbox_wa.')\n",
    "\n",
    "subbasins_gdf = gpd.GeoDataFrame(pd.concat(records, ignore_index=True), crs='EPSG:4326')\n",
    "subbasins_gdf = subbasins_gdf.rename(columns={'name': 'huc_name', code_col: 'huc_code'})\n",
    "\n",
    "# Dissolve to one polygon per basin_name (for basin-level station association)\n",
    "basins_gdf = subbasins_gdf.dissolve(by='basin_name', as_index=False)[['basin_name', 'geometry']]\n",
    "\n",
    "# Attach the list of HUC codes used for each basin (string for CSV friendliness)\n",
    "codes_by_basin = (\n",
    "    subbasins_gdf.groupby('basin_name')['huc_code']\n",
    "    .apply(lambda s: ';'.join(sorted(set(s.astype(str)))))\n",
    "    .reset_index()\n",
    "    .rename(columns={'huc_code': 'huc_code'})\n",
    ")\n",
    "basins_gdf = basins_gdf.merge(codes_by_basin, on='basin_name', how='left')\n",
    "\n",
    "total_unique_hucs = subbasins_gdf['huc_code'].nunique()\n",
    "print('-' * 70)\n",
    "print(f\"Matched HUC polygons: {len(subbasins_gdf)} (unique HUC codes: {total_unique_hucs})\")\n",
    "print('  subbasins_gdf rows:', len(subbasins_gdf))\n",
    "print('  basins_gdf rows:', len(basins_gdf))\n",
    "display(basins_gdf[['basin_name', 'huc_code']])\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75abbb5",
   "metadata": {},
   "source": [
    "## Step 2: Fetch Seismic Stations (UW, CC)\n",
    "\n",
    "Query station metadata from the FDSN provider and convert results to a GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dec18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch stations for UW + CC networks within bbox_wa\n",
    "client = Client(fdsn_provider)\n",
    "\n",
    "networks = network_filter if network_filter is not None else None\n",
    "network_arg = ','.join(networks) if networks else '*'\n",
    "\n",
    "print(f\"Requesting stations from {fdsn_provider} for network={network_arg}\")\n",
    "inv = client.get_stations(\n",
    "    network=network_arg,\n",
    "    level='station',\n",
    "    minlongitude=bbox_wa[0],\n",
    "    minlatitude=bbox_wa[1],\n",
    "    maxlongitude=bbox_wa[2],\n",
    "    maxlatitude=bbox_wa[3],\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for net in inv:\n",
    "    for sta in net:\n",
    "        rows.append(\n",
    "            {\n",
    "                'network': net.code,\n",
    "                'station': sta.code,\n",
    "                'latitude': float(sta.latitude),\n",
    "                'longitude': float(sta.longitude),\n",
    "                'elevation_m': float(sta.elevation) if sta.elevation is not None else np.nan,\n",
    "                'start_date': getattr(sta, 'start_date', None),\n",
    "                'end_date': getattr(sta, 'end_date', None),\n",
    "            }\n",
    ")\n",
    "\n",
    "stations_df = pd.DataFrame(rows)\n",
    "if len(stations_df) == 0:\n",
    "    raise RuntimeError('No stations returned. Check bbox_wa, network_filter, and fdsn_provider.')\n",
    "\n",
    "# Optional elevation filter\n",
    "if elev_min is not None:\n",
    "    stations_df = stations_df[stations_df['elevation_m'] >= float(elev_min)]\n",
    "if elev_max is not None:\n",
    "    stations_df = stations_df[stations_df['elevation_m'] <= float(elev_max)]\n",
    "\n",
    "stations_gdf = gpd.GeoDataFrame(\n",
    "    stations_df,\n",
    "    geometry=gpd.points_from_xy(stations_df['longitude'], stations_df['latitude']),\n",
    "    crs='EPSG:4326',\n",
    ")\n",
    "\n",
    "print(f\"Stations fetched: {len(stations_gdf)}\")\n",
    "display(stations_gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfed49d",
   "metadata": {},
   "source": [
    "## Step 3: Associate Stations with Basins/Sub-basins\n",
    "\n",
    "Spatially join station points to dissolved basins and to sub-basin HUC polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60066da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basin-level join (dissolved polygons)\n",
    "stations_basin = gpd.sjoin(\n",
    "    stations_gdf,\n",
    "    basins_gdf[['basin_name', 'geometry']],\n",
    "    how='left',\n",
    "    predicate='within',\n",
    ")\n",
    "stations_basin = stations_basin.drop(columns=[c for c in ['index_right'] if c in stations_basin.columns])\n",
    "\n",
    "# Sub-basin join (HUC polygons)\n",
    "stations_subbasin = gpd.sjoin(\n",
    "    stations_gdf,\n",
    "    subbasins_gdf[['basin_name', 'huc_code', 'huc_name', 'geometry']],\n",
    "    how='left',\n",
    "    predicate='within',\n",
    ")\n",
    "stations_subbasin = stations_subbasin.drop(columns=[c for c in ['index_right'] if c in stations_subbasin.columns])\n",
    "\n",
    "key_cols = ['network', 'station']\n",
    "\n",
    "# If a station falls into multiple polygons, keep the first match deterministically\n",
    "stations_basin_first = stations_basin.sort_values(key_cols).drop_duplicates(subset=key_cols)\n",
    "stations_subbasin_first = stations_subbasin.sort_values(key_cols).drop_duplicates(subset=key_cols)\n",
    "\n",
    "stations_with_basins = stations_gdf.merge(\n",
    "    stations_basin_first[key_cols + ['basin_name']].rename(columns={'basin_name': 'basin_name_basin'}),\n",
    "    on=key_cols,\n",
    "    how='left',\n",
    ")\n",
    "stations_with_basins = stations_with_basins.merge(\n",
    "    stations_subbasin_first[key_cols + ['basin_name', 'huc_code', 'huc_name']].rename(\n",
    "        columns={'basin_name': 'basin_name_subbasin'}\n",
    "    ),\n",
    "    on=key_cols,\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "# Prefer subbasin-derived basin name when present\n",
    "stations_with_basins['basin_name'] = stations_with_basins['basin_name_subbasin'].combine_first(\n",
    "    stations_with_basins['basin_name_basin']\n",
    " )\n",
    "\n",
    "stations_with_basins = stations_with_basins.drop(columns=['basin_name_basin', 'basin_name_subbasin'])\n",
    "\n",
    "assigned = stations_with_basins['basin_name'].notna().sum()\n",
    "print(f\"Stations assigned to a basin: {assigned} / {len(stations_with_basins)}\")\n",
    "display(stations_with_basins[['network','station','basin_name','huc_code','huc_name']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb278f68",
   "metadata": {},
   "source": [
    "## Step 4: QC Map (Basins + Stations)\n",
    "\n",
    "Color-code each basin and plot associated stations on top for visual QA/QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Create a stable color map for basin names\n",
    "basin_list = list(basins_gdf['basin_name'])\n",
    "cmap = plt.get_cmap('tab20', max(len(basin_list), 1))\n",
    "basin_colors = {name: cmap(i) for i, name in enumerate(basin_list)}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot basins\n",
    "basins_gdf.plot(\n",
    "    ax=ax,\n",
    "    facecolor=basins_gdf['basin_name'].map(basin_colors),\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8,\n",
    "    alpha=0.35,\n",
    ")\n",
    "\n",
    "# Plot stations\n",
    "assigned_mask = stations_with_basins['basin_name'].notna()\n",
    "assigned_gdf = stations_with_basins[assigned_mask].copy()\n",
    "unassigned_gdf = stations_with_basins[~assigned_mask].copy()\n",
    "\n",
    "if len(assigned_gdf) > 0:\n",
    "    assigned_gdf.plot(\n",
    "        ax=ax,\n",
    "        markersize=25,\n",
    "        color=assigned_gdf['basin_name'].map(basin_colors),\n",
    "        edgecolor='white',\n",
    "        linewidth=0.4,\n",
    "        zorder=5,\n",
    "    )\n",
    "\n",
    "if len(unassigned_gdf) > 0:\n",
    "    unassigned_gdf.plot(\n",
    "        ax=ax,\n",
    "        markersize=35,\n",
    "        color='black',\n",
    "        marker='x',\n",
    "        zorder=6,\n",
    "    )\n",
    "\n",
    "# Legend\n",
    "legend_handles = [mpatches.Patch(color=basin_colors[n], label=n) for n in basin_list]\n",
    "if len(unassigned_gdf) > 0:\n",
    "    legend_handles.append(mpatches.Patch(color='black', label='Unassigned (outside basins)'))\n",
    "ax.legend(handles=legend_handles, loc='upper right', frameon=True)\n",
    "\n",
    "ax.set_title('Basins (dissolved) + UW/CC Stations (color-coded by basin)')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Tighten to bbox (with a small pad)\n",
    "minlon, minlat, maxlon, maxlat = bbox_wa\n",
    "pad_lon = (maxlon - minlon) * 0.02\n",
    "pad_lat = (maxlat - minlat) * 0.02\n",
    "ax.set_xlim(minlon - pad_lon, maxlon + pad_lon)\n",
    "ax.set_ylim(minlat - pad_lat, maxlat + pad_lat)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "qc_path = output_dir / 'qc_basins_stations.png'\n",
    "fig.savefig(qc_path, dpi=200, bbox_inches='tight')\n",
    "print(f\"Saved QC map: {qc_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109e3db",
   "metadata": {},
   "source": [
    "## Step 5: Export CSV\n",
    "\n",
    "Write station metadata + basin/HUC assignment to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export station assignments to CSV\n",
    "csv_path = output_dir / 'stations_by_basin.csv'\n",
    "\n",
    "export_cols = [\n",
    "    'network',\n",
    "    'station',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'elevation_m',\n",
    "    'basin_name',\n",
    "    'huc_code',\n",
    "    'huc_name',\n",
    "    'start_date',\n",
    "    'end_date',\n",
    "]\n",
    "\n",
    "stations_out = stations_with_basins.copy()\n",
    "for c in export_cols:\n",
    "    if c not in stations_out.columns:\n",
    "        stations_out[c] = np.nan\n",
    "\n",
    "stations_out = pd.DataFrame(stations_out[export_cols])\n",
    "stations_out.to_csv(csv_path, index=False)\n",
    "print(f\"Wrote CSV: {csv_path} ({len(stations_out)} rows)\")\n",
    "\n",
    "display(stations_out.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaia-hazlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
